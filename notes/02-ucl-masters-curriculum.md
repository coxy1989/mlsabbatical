## [UCL Masters](http://www.cs.ucl.ac.uk/prospective_students/msc_machine_learning/)

[module list](http://www.cs.ucl.ac.uk/prospective_students/msc_machine_learning/)
[module directory](http://www.cs.ucl.ac.uk/current_students/syllabus/)

### Compulsory / Core Modules

#### COMP0078 - [Supervised Learning](http://www.cs.ucl.ac.uk/current_students/syllabus/compgi/compgi01_supervised_learning/) (15 credits)


The course consists of both foundational topics for supervised learning such as Linear Regression, Nearest Neighbors and Kernelisation as well contemporary research areas such as multi-task learning and optimisation via proximal methods. In a given year topics will be drawn non-exclusively from the following.

- Nearest Neighbors
- Linear Regression
- Kernels and Regularisation
- Support Vector Machines
- Gaussian Processes
- Decision Trees
- Ensemble Learning
- Sparsity Methods
- Multi-task Learning
- Proximal Methods
- Semi-supervised Learning
- Neural Networks
- Matrix Factorization
- Online Learning
- Statistical Learning Theory

Problem Sets and reading list and slides available from [here](http://www0.cs.ucl.ac.uk/staff/M.Herbster/GI01/)

Reading list from link above:

Main reference:

- The Elements of Statistical Learning: Data Mining, Inference, and Prediction. Springer, 2002. T. Hastie, R. Tibshirani and J. Friedman.

Other suggested references:

- Pattern Recognition and Machine Learning Springer, 2006. C.M. Bishop.
- An Introduction to Support Vector Machines Cambridge University Press, 2001. N. Cristianini and J. Shawe-Taylor.
- Pattern Classification. Wiley, 2nd edition, 2004. R.O. Duda, P.E. Hart and D.G. Stork.
- Information Theory, Pattern Recognition and Neural Networks. Cambridge Press, 2003. D.J.C. MacKay.
- Machine Learning. McGraw Hill, 1997. T. Mitchell.
- Kernel Methods for Pattern Analysis. Cambridge University Press, 2004. J. Shawe-Taylor and N. Cristianini.
- Learning with Kernels. MIT Press, 2002. B.Scholkopf and A.J. Smola.
- Statistical Learning Theory. Wiley, New York, 1998. V.N. Vapnik.


#### COMP0091 - Individual Project (60 credits)

There is no set syllabus: students identify their chosen project area and are allocated a supervisor who is a member of academic staff. The supervisor provides support and guidance


### Optional Modules

Choose a minimum of 75 credits and a maximum of 90 credits from these optional modules.

Students must take either COMP0080 or COMP0086.

#### [COMP0080 - Graphical Models](http://www.cs.ucl.ac.uk/current_students/syllabus/compgi/compgi08_graphical_models/) (15 credits)

To give an introduction to probabilistic modelling covering the broad theoretical landscape.

The course aims to cover much of the first 12 chapters of the course textbook www.cs.ucl.ac.uk/staff/d.barber/brml/

The emphasis is on probabilistic modelling of discrete variables.

- Bayesian Reasoning
- Bayesian Networks
- Directed and Undirected Graphical Models
- Inference in Singly-Connected Graphs
- Hidden Markov Models
- Junction Tree Algorithm
- Decision Making under uncertainty
- Markov Decision Processes
- Learning with Missing Data
- Approximate Inference using Sampling
- If time permits we will also cover some deterministic approximate inference.

Reading List

- Bayesian reasoning and machine learning - David Barber 2012

#### [COMP0086 - Probabilistic and Unsupervised Learning]() (15 credits)

This course provides students with an in-depth introduction to statistical modelling and unsupervised learning techniques It presents probabilistic approaches to modelling and their relation to coding theory and Bayesian statistics. A variety of latent variable models will be covered including mixture models (used for clustering), dimensionality reduction methods, time series models such as hidden Markov models which are used in speech recognition and bioinformatics, independent components analysis, hierarchical models, and nonlinear models. The course will present the foundations of probabilistic graphical models (e.g. Bayesian networks and Markov networks) as an overarching framework for unsupervised modelling. We will cover Markov chain Monte Carlo sampling methods and variational approximations for inference. Time permitting, students will also learn about other topics in probabilistic (or Bayesian) machine learning.

- Basics of Bayesian learning and regression.
- Latent variable models, including mixture models and factor models.
- The Expectation-Maximisation (EM) algorithm.
- Time series, including hidden Markov models and state-space models.
- Spectral learning.
- Graphical representations of probabilistic models.
- Belief propagation, junction trees and message passing.
- Model selection, hyperparameter optimisation and Gaussian-process regression.

Reading List

- Information theory, inference, and learning algorithms - David J. C. MacKay c2003

#### [COMP0089 - Advanced Deep Learning and Reinforcement Learning (15 credits)](http://www.cs.ucl.ac.uk/current_students/syllabus/compgi/compgi22_advanced_deep_learning_and_reinforcement_learning/)

#### [COMP0083 - Advanced Topics in Machine Learning](http://www.cs.ucl.ac.uk/current_students/syllabus/compgi/compgi13_advanced_topics_in_machine_learning/) (15 credits)

#### [COMP0053 - Affective Computing and Human-Robot Interaction](http://www.cs.ucl.ac.uk/current_students/syllabus/compgi/compgi17_affective_computing_and_human_robot_interaction/) (15 credits)

#### [COMP0081 - Applied Machine Learning](http://www.cs.ucl.ac.uk/current_students/syllabus/compgi/compgi09_applied_machine_learning/) (15 credits)

#### [COMP0085 - Approximate Inference and Learning in Probabilistic Models](http://www.cs.ucl.ac.uk/current_students/syllabus/compgi/compgi16_approximate_inference_and_learning_in_probabilistic_models/) (15 credits)

#### [COMP0082 - Bioinformatics](http://www.cs.ucl.ac.uk/current_students/syllabus/compgi/compgi10_bioinformatics/) (15 credits)

#### [COMP0084 - Information Retrieval and Data Mining](http://www.cs.ucl.ac.uk/current_students/syllabus/compgi/compgi15_information_retrieval_data_mining/) (15 credits)

#### [COMP0090 - Introduction to Deep Learning](http://www.cs.ucl.ac.uk/current_students/syllabus/compgi/compgi23_introduction_to_deep_learning/) (15 credits)

#### [COMP0137 - Machine Vision](http://www.cs.ucl.ac.uk/current_students/syllabus/compgi/compgi14_machine_vision/) (15 credits)

#### [COMP0087 - Statistical Natural Language Processing](http://www.cs.ucl.ac.uk/current_students/syllabus/compgi/compgi19_statistical_natural_language_processing/) (15 credits)


### Elective Modules

- [COMP0118 - Computational Modelling for Biomedical Imaging](http://www.cs.ucl.ac.uk/current_students/syllabus/compgv/compgv17_computational_modelling_for_biomedical_imaging/) (15 credits)

- [COMP0114 - Inverse Problems in Imaging](http://www.cs.ucl.ac.uk/current_students/syllabus/compgv/compgv08_inverse_problems_in_imaging/) (15 credits)

- [COMP0120 - Numerical Optimisation](http://www.cs.ucl.ac.uk/current_students/syllabus/compgv/compgv19_numerical_optimisation/) (15 credits)

- [COMP0128 - Robotic Control Theory and Systems](http://www.cs.ucl.ac.uk/current_students/syllabus/compgx/compgx02_robotic_control_theory_and_systems/) (15 credits)

- [COMP0127 - Robotic Systems Engineering](http://www.cs.ucl.ac.uk/current_students/syllabus/compgx/compgx01_robotic_systems_engineering/) (15 credits)

Choose a minimum of 15 credits and a maximum of 30 credits from these elective modules.

