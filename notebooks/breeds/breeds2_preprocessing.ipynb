{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision as tv\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from ipywidgets import interact, interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
       "      <td>dingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
       "      <td>pekinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
       "      <td>bluetick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
       "      <td>golden_retriever</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id             breed\n",
       "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
       "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
       "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
       "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
       "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = '/home/ubuntu/data/dogbreed'\n",
    "labels_df = pd.read_csv(f'{DATA_PATH}/labels.csv')\n",
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# - (1) Rescale images to have shortest side of 340px.\n",
    "# - (2) Take center 224 x 224 crop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = '/home/ubuntu/data/dogbreed/train'\n",
    "dest_dir = '/home/ubuntu/data/dogbreed/tmp/funk/340'\n",
    "img_names = labels_df['id'].map(lambda id: id + '.jpg')\n",
    "transform_files(img_names, source_dir, dest_dir, partial(resize_image, 340))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5636d2962b5f4ec28e5627dd5607cbee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='idx', max=10221), Output()), _dom_classes=('widget-interâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.show_input_image(idx)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_input_image(idx):\n",
    "    img = pil_tform(Image.open(f'{dest_dir}/{img_names.iloc[idx]}'))\n",
    "    plt.imshow(img)\n",
    "\n",
    "img_names = labels_df['id'].map(lambda id: id + '.jpg')\n",
    "pil_tform = tv.transforms.Compose([\n",
    "    tv.transforms.RandomRotation(10),\n",
    "    tv.transforms.ColorJitter(0.05,0.05,0.05,0.05),\n",
    "    tv.transforms.RandomHorizontalFlip(0.5),\n",
    "    tv.transforms.CenterCrop(224)])\n",
    "interact(show_input_image, idx=widgets.IntSlider(min=0, max=img_names.shape[0] -1 , value = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratchpad while training in the other notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from resnext_101_64x4d import resnext_101_64x4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnext_101_64x4d()\n",
    "model.load_state_dict(torch.load('/home/ubuntu/data/weights/resnext_101_64x4d.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cond_init(m, init_fn):\n",
    "    if not isinstance(m, (torch.nn.BatchNorm1d, torch.nn.BatchNorm2d, torch.nn.BatchNorm3d)):\n",
    "        if hasattr(m, 'weight'): init_fn(m.weight)\n",
    "        if hasattr(m, 'bias') and hasattr(m.bias, 'data'): m.bias.data.fill_(0.)\n",
    "\n",
    "def apply_init(m, init_fn):\n",
    "    m.apply(lambda x: cond_init(x, init_fn))\n",
    "\n",
    "    \n",
    "#apply_init(model, torch.nn.init.kaiming_normal)\n",
    "\n",
    "#model.apply(lambda submodule: cond_init(submodule, torch.nn.init.kaiming_normal_))\n",
    "\n",
    "#cond_init(model, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------\n",
    "# TODO\n",
    "\n",
    "# - Match fast.ai default performance.\n",
    "# - Learning rate jazz\n",
    "#   - Cyclical learning rates: https://arxiv.org/abs/1506.01186\n",
    "#   - Setting the learning rate: https://towardsdatascience.com/estimating-optimal-learning-rate-for-a-deep-neural-network-ce32f2556ce0\n",
    "#   - LR finder\n",
    "# - The rest of JH's training tricks\n",
    "# - Sanity - composable traning loop\n",
    "# - TTA\n",
    "\n",
    "# annoyances\n",
    "# -- Speed - check against fast.ai, check you're not missing any optimisations\n",
    "# -- Pytorch transforms seem slow; is handrolled opencv implementation faster?\n",
    "# -- Store best weights as you go\n",
    "# -- Load / Save weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
