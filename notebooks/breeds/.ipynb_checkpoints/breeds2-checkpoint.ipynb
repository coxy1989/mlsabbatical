{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import itertools\n",
    "import torchvision as tv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import dataset, DataLoader, Dataset\n",
    "from PIL import Image\n",
    "from functools import partial\n",
    "from ipywidgets import interact, interactive\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>breed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000bec180eb18c7604dcecc8fe0dba07</td>\n",
       "      <td>boston_bull</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>001513dfcb2ffafc82cccf4d8bbaba97</td>\n",
       "      <td>dingo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001cdf01b096e06d78e9e5112d419397</td>\n",
       "      <td>pekinese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00214f311d5d2247d5dfe4fe24b2303d</td>\n",
       "      <td>bluetick</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0021f9ceb3235effd7fcde7f7538ed62</td>\n",
       "      <td>golden_retriever</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id             breed\n",
       "0  000bec180eb18c7604dcecc8fe0dba07       boston_bull\n",
       "1  001513dfcb2ffafc82cccf4d8bbaba97             dingo\n",
       "2  001cdf01b096e06d78e9e5112d419397          pekinese\n",
       "3  00214f311d5d2247d5dfe4fe24b2303d          bluetick\n",
       "4  0021f9ceb3235effd7fcde7f7538ed62  golden_retriever"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = '/home/ubuntu/data/dogbreed'\n",
    "pd.read_csv(f'{DATA_PATH}/labels.csv').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class DogsDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, labels_df, data_path, transform=None):\n",
    "        super().__init__()\n",
    "        self.labels_df = labels_df\n",
    "        self.data_path = data_path\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.labels_df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.labels_df.iloc[idx]\n",
    "        id, breed = row['id'], row['breed']\n",
    "        img = Image.open(f'{self.data_path}/train/{id}.jpg')\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, breed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x375 at 0x7FEB82D1C470>,\n",
       " 'boston_bull')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "next(iter(DogsDataset(pd.read_csv(f'{DATA_PATH}/labels.csv'), DATA_PATH)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def gen_split_indexes(train_size=0.8):\n",
    "    idxs = range(0, labels.shape[0])\n",
    "    perm = np.random.permutation(idxs)\n",
    "    split_idx = int(0.8 * len(perm))\n",
    "    return perm[:split_idx], perm[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def resize_image(target_size, image_path):\n",
    "    image = Image.open(image_path)\n",
    "    w, h = image.size\n",
    "    target_ratio = target_size / min(w, h)\n",
    "    new_w = np.floor(max(w * target_ratio, target_size))\n",
    "    new_h = np.floor(max(h * target_ratio, target_size))\n",
    "    return image.resize((int(new_w), int(new_h)))\n",
    "\n",
    "def transform_files(file_names, source_dir, dest_dir, tform):\n",
    "    for name in file_names:\n",
    "        file = tform(f'{source_dir}/{name}')\n",
    "        file.save(f'{dest_dir}/{name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(f'{DATA_PATH}/labels.csv')\n",
    "breed_lookup = {breed : idx for idx, breed in enumerate(sorted(labels_df['breed'].unique()))}\n",
    "labels_df['breed'] = labels_df['breed'].map(breed_lookup)\n",
    "train_idxs, val_idxs = gen_split_indexes(labels_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "len(train_idxs) + len(val_idxs) == labels_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Preprocessing:\n",
    "# - (1) Rescale images to have shortest side of 340px.\n",
    "# - (2) Take center 224 x 224 crop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# (1) Rescale images to have shortest side of 340px\n",
    "source_dir = '/home/ubuntu/data/dogbreed/train'\n",
    "dest_dir = '/home/ubuntu/data/dogbreed/tmp/funk/340'\n",
    "img_names = labels['id'].map(lambda id: id + '.jpg')\n",
    "transform_files(img_names, source_dir, dest_dir, partial(resize_image, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# (2) Take random 224 x 224 crop\n",
    "pil_tform = tv.transforms.CenterCrop(224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90cafaa7052f4cef9bef38b119ec2dcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='idx', max=10221), Output()), _dom_classes=('widget-interâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.show_input_image(idx)>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity_check\n",
    "def show_input_image(idx):\n",
    "    img = pil_tform(Image.open(f'{dest_dir}/{img_names.iloc[idx]}'))\n",
    "    plt.imshow(img)\n",
    "    \n",
    "interact(show_input_image, idx=widgets.IntSlider(min=0, max=img_names.shape[0] -1 , value = 0))\n",
    "\n",
    "# TODO:\n",
    "# - scaling, reflections..etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "class SimpleCNN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.cv_layers = torch.nn.Sequential(torch.nn.Conv2d(3, 8, kernel_size=7, stride=1, padding=3),\n",
    "                                             torch.nn.ReLU(),\n",
    "                                             torch.nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                                             torch.nn.Conv2d(8, 16, kernel_size=3, stride=1, padding=1),\n",
    "                                             torch.nn.ReLU(),\n",
    "                                             torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.fc_layers = torch.nn.Sequential(torch.nn.Linear(16 * 56 * 56, 1028),\n",
    "                                             torch.nn.ReLU(),\n",
    "                                             torch.nn.Linear(1028, 120),\n",
    "                                             torch.nn.ReLU())\n",
    "    def forward(self, x):\n",
    "        x = self.cv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc_layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 120])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sanity check\n",
    "model = SimpleCNN()\n",
    "tensor = (tv.transforms.ToTensor()(pil_tform(Image.open(f'{dest_dir}/{img_names.iloc[0]}')))).unsqueeze(0)\n",
    "model(tensor).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def train_epoch(trainloader, model, criterion, optimizer, print_freq=100):\n",
    "    ''' run a single epoch of training'''\n",
    "    model.train()\n",
    "    for idx, (input, target) in enumerate(tqdm(trainloader)):\n",
    "        output = model(input.to(device))\n",
    "        loss = criterion(output, target.to(device))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def accuracy(output, target):\n",
    "    _, preds = output.max(1)\n",
    "    return (preds == target).double().mean()\n",
    "\n",
    "def evaluate(validationloader, model):\n",
    "    '''evaluate the model'''\n",
    "    model.eval()\n",
    "    correct_cum = n = 0\n",
    "    for idx, (input, target) in enumerate(validationloader):\n",
    "        output = model(input.to(device))\n",
    "        _, preds = output.max(1)\n",
    "        correct_cum += (preds == target.to(device)).double().sum()\n",
    "        n += len(target)\n",
    "    return (correct_cum / n).item()\n",
    "        \n",
    "def fit(model, trainloader, validationloader, learn_rate, epochs):\n",
    "    criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), learn_rate, momentum=0.9, weight_decay=1e-4)\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_epoch(trainloader, model, criterion, optimizer)\n",
    "        val_acc = evaluate(validationloader, model)\n",
    "        train_acc = evaluate(trainloader, model)\n",
    "        print(f' train accuracy: {train_acc} \\n validation accuracy: {val_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03129584352078239"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(validationloader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "952aeec297cf4e01ad943d26c614ad84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1023), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train accuracy: 0.011617952794423384 \n",
      " validation accuracy: 0.007823960880195598\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f2ef11b54f4b6691fb674ad6001652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1023), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train accuracy: 0.015531368472544944 \n",
      " validation accuracy: 0.011246943765281172\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e8cd0e98d62459bbcde834036979df8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1023), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train accuracy: 0.0298397945456769 \n",
      " validation accuracy: 0.019559902200488997\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce8be102ea6440adb41ed7219cef4813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1023), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train accuracy: 0.038889568301333007 \n",
      " validation accuracy: 0.027383863080684592\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c9eb79b96a1489483165d711d9c3bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1023), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train accuracy: 0.058212058212058215 \n",
      " validation accuracy: 0.035207823960880194\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "bs = 8\n",
    "n_work = 1\n",
    "learn_rate = 1e-3\n",
    "\n",
    "train_labels_df = labels_df.iloc[train_idxs].reset_index(drop=True)\n",
    "val_labels_df = labels_df.iloc[val_idxs].reset_index(drop=True)\n",
    "tfm = tv.transforms.Compose([pil_tform, tv.transforms.ToTensor()])\n",
    "train_ds = DogsDataset(train_labels_df, DATA_PATH, transform=tfm)\n",
    "val_ds = DogsDataset(val_labels_df, DATA_PATH, transform=tfm)\n",
    "\n",
    "trainloader = DataLoader(train_ds, batch_size=bs, shuffle=True, num_workers=n_work, pin_memory=True)\n",
    "validationloader = DataLoader(val_ds, batch_size=bs, shuffle=True, num_workers=n_work, pin_memory=True)\n",
    "\n",
    "model = SimpleCNN().to(device)\n",
    "fit(model, trainloader, validationloader, learn_rate, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------\n",
    "# POSSIBILITES\n",
    "# - transfer learning tutorial, fast.ai lesson + implement \n",
    "# - JH's training tricks\n",
    "# - LR finder"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
