{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import patsy as pt\n",
    "import pandas as pd\n",
    "from sklearn import model_selection, metrics, linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm\n",
    "\n",
    "- In the forward direction: refit the model with each of the remaining predictors and incorporate the one which brings about the greatest improvement in performance.\n",
    "- In the reverse direction: refit the model dropping each of the remaining predictors and remove the one which leads to the smallest reduction in performance.\n",
    "- There are $1 + \\frac{p(1 + p)}{2}$ combinations to consider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching over 16 models\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9851503701807045,\n",
       " 0.9674423640652615,\n",
       " 0.9027743210969267,\n",
       " 0.7958948240026296,\n",
       " 0.599751372208384,\n",
       " 0.0]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stepwise(X, y, forward=True):\n",
    "    p = X.shape[1]\n",
    "    print('Searching over {} models'.format(int(1 + ((p * (1 + p))/2))))\n",
    "    # begin with no selections, `best` will be mutated as the algorithm runs.\n",
    "    # `best` is the vector representing the current best combination of predictors.\n",
    "    best = np.repeat(0, p)\n",
    "    \n",
    "    selection = best if forward else np.logical_not(best)\n",
    "    Xf = X @ np.diag(selection)\n",
    "    model = linear_model.LinearRegression().fit(Xf, y)\n",
    "    score = model.score(X, y)\n",
    "\n",
    "    scores = [score]\n",
    "    models = [model]\n",
    "    vectors = [best]\n",
    "    \n",
    "    while not np.array_equal(best, np.repeat(1, p)):\n",
    "        selection_matrix = np.identity(p) @ np.diag(np.logical_not(best))\n",
    "        best_vector = None\n",
    "        best_score = None\n",
    "        best_model = None\n",
    "        for c in selection_matrix.T:\n",
    "            if np.array_equal(c, np.zeros(len(c))):\n",
    "                continue\n",
    "            trace = c + best\n",
    "            selection = trace if forward else np.logical_not(trace)\n",
    "            Xf = X @ np.diag(selection)\n",
    "            model = linear_model.LinearRegression().fit(Xf, y)\n",
    "            score = model.score(X, y)\n",
    "            if best_score == None or score > best_score:\n",
    "                best_vector = c\n",
    "                best_score = score\n",
    "                best_model = model\n",
    "        best = best + best_vector\n",
    "        scores.append(best_score)\n",
    "        models.append(best_model)\n",
    "        vectors.append(best)\n",
    "    return scores, models, vectors\n",
    "\n",
    "n = 100\n",
    "p = 5\n",
    "X = np.random.normal(1,1,(n, p))\n",
    "eps = np.random.normal(1,1, n).reshape(-1,1)\n",
    "beta = np.arange(1, p + 1).reshape(-1,1)\n",
    "y = (X @ beta) + eps\n",
    "\n",
    "scores, models, vectors = stepwise(X,y, forward=False)\n",
    "\n",
    "scores\n",
    "\n",
    "# TODO\n",
    "# - remove the nasty if at the top of the loop\n",
    "# - add comments\n",
    "# - factor out repeated model fit / selection code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate some data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example 1: All predictors are equally associated with the outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "p = 10\n",
    "beta = np.repeat(2, p).reshape(-1, 1)\n",
    "X = np.random.normal(0, 1, (n, p))\n",
    "y = X @ beta\n",
    "#train, test = model_selection.train_test_split(X, test_size=0.2)\n",
    "\n",
    "#stepwise(train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
